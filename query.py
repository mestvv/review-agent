import chromadb
from sentence_transformers import SentenceTransformer
from langchain_openai import ChatOpenAI
from langchain_core.prompts import PromptTemplate

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
CHROMA_DB_PATH = "./chroma_db"
COLLECTION_NAME = "literature_review"

client = chromadb.PersistentClient(path=CHROMA_DB_PATH)
collection = client.get_or_create_collection(name=COLLECTION_NAME)
model = SentenceTransformer("mlsa-iai-msu-lab/sci-rus-tiny")

llm = ChatOpenAI(
    model="deepseek/deepseek-r1-0528-qwen3-8b",
    base_url="http://localhost:1234/v1",
    api_key="lm-studio",
    temperature=0.1,
)


def retrieve_context(question, n_results=5):
    """–ü–æ–ª—É—á–∞–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö."""
    query_embedding = model.encode([question])
    results = collection.query(
        query_embeddings=query_embedding.tolist(),
        n_results=n_results,
        include=["documents", "metadatas"],
    )
    return results["documents"][0], results["metadatas"][0]


def ask(question, n_results=5):
    """–û—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –Ω–∞ –æ—Å–Ω–æ–≤–µ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""
    documents, metadatas = retrieve_context(question, n_results)
    context = "\n\n---\n\n".join(documents)

    prompt = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ù–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –æ—Ç–≤–µ—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å.

–ö–û–ù–¢–ï–ö–°–¢:
{context[:3000]}

–í–û–ü–†–û–°: {question}

–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ, —Å—Å—ã–ª–∞—è—Å—å –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏."""

    response = llm.invoke(prompt)

    # –î–æ–±–∞–≤–ª—è–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    sources = set(m["document"] for m in metadatas)
    return f"{response.content}\n\n–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {', '.join(sources)}"


# === –û–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã ===

REVIEW_PROMPT = PromptTemplate(
    input_variables=["topic", "context", "sources"],
    template="""–¢—ã –Ω–∞—É—á–Ω—ã–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –ù–∞–ø–∏—à–∏ –æ–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –Ω–∞ —Ç–µ–º—É "{topic}".

–ò–ó–í–õ–ï–ß–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´ –ò–ó –°–¢–ê–¢–ï–ô:
{context}

–ò–°–¢–û–ß–ù–ò–ö–ò: {sources}

–ò–ù–°–¢–†–£–ö–¶–ò–ò:
1. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π –∏ —Å–∏–Ω—Ç–µ–∑–∏—Ä—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
2. –í—ã–¥–µ–ª–∏ –∫–ª—é—á–µ–≤—ã–µ —Ç–µ–º—ã –∏ —Ç–µ–Ω–¥–µ–Ω—Ü–∏–∏
3. –£–∫–∞–∂–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏–ª–∏ –ø—Ä–æ–±–µ–ª—ã –≤ –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å)
4. –°—Å—ã–ª–∞–π—Å—è –Ω–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
5. –ü–∏—à–∏ –≤ –Ω–∞—É—á–Ω–æ–º —Å—Ç–∏–ª–µ

–°–¢–†–£–ö–¢–£–†–ê –û–ë–ó–û–†–ê:
- –í–≤–µ–¥–µ–Ω–∏–µ (–∞–∫—Ç—É–∞–ª—å–Ω–æ—Å—Ç—å —Ç–µ–º—ã)
- –û—Å–Ω–æ–≤–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π
- –û–±—Å—É–∂–¥–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥—ã
- –°–ø–∏—Å–æ–∫ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤""",
)


def generate_review(topic, n_results=15):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã –ø–æ –∑–∞–¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ."""
    # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã
    documents, metadatas = retrieve_context(topic, n_results)

    if not documents:
        return "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ –≤ –±–∞–∑–µ."

    context = "\n\n---\n\n".join(documents)
    sources = list(set(m["document"] for m in metadatas))

    chain = REVIEW_PROMPT | llm
    response = chain.invoke(
        {
            "topic": topic,
            "context": context[:6000],
            "sources": ", ".join(sources),
        }
    )

    return response.content


def stream_review(topic, n_results=15):
    """–°—Ç—Ä–∏–º–∏—Ç –æ–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã."""
    documents, metadatas = retrieve_context(topic, n_results)

    if not documents:
        yield "–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ –≤ –±–∞–∑–µ."
        return

    context = "\n\n---\n\n".join(documents)
    sources = list(set(m["document"] for m in metadatas))

    chain = REVIEW_PROMPT | llm

    for chunk in chain.stream(
        {
            "topic": topic,
            "context": context[:6000],
            "sources": ", ".join(sources),
        }
    ):
        yield getattr(chunk, "content", str(chunk))


# === Gradio –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å ===

import gradio as gr


def review_interface(topic):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±–∑–æ—Ä–∞."""
    if not topic.strip():
        yield "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–º—É –¥–ª—è –æ–±–∑–æ—Ä–∞."
        return

    review_text = ""
    for token in stream_review(topic):
        review_text += token
        yield review_text


def qa_interface(question):
    """–ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å –¥–ª—è Q&A."""
    if not question.strip():
        return "–í–≤–µ–¥–∏—Ç–µ –≤–æ–ø—Ä–æ—Å."
    return ask(question)


with gr.Blocks(title="Literature Review Agent") as demo:
    gr.Markdown("# üìö –ê–≥–µ–Ω—Ç –æ–±–∑–æ—Ä–∞ –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã")

    with gr.Tab("–û–±–∑–æ—Ä –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä—ã"):
        topic_input = gr.Textbox(
            label="–¢–µ–º–∞ –æ–±–∑–æ—Ä–∞",
            placeholder="–í–ª–∏—è–Ω–∏–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è –∫–ª–∏–º–∞—Ç–∞ –Ω–∞ –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–µ–º–µ—Ä–∑–ª—ã–µ –≥—Ä—É–Ω—Ç—ã",
        )
        review_btn = gr.Button("–°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –æ–±–∑–æ—Ä", variant="primary")
        review_output = gr.Markdown(label="–û–±–∑–æ—Ä")
        review_btn.click(review_interface, topic_input, review_output)

    with gr.Tab("–í–æ–ø—Ä–æ—Å-–û—Ç–≤–µ—Ç"):
        question_input = gr.Textbox(
            label="–í–æ–ø—Ä–æ—Å",
            placeholder="–ö–∞–∫ –∏–∑–º–µ–Ω—è–µ—Ç—Å—è —Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ –≤–µ—á–Ω–æ–π –º–µ—Ä–∑–ª–æ—Ç—ã?",
        )
        qa_btn = gr.Button("–ü–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç", variant="primary")
        qa_output = gr.Markdown(label="–û—Ç–≤–µ—Ç")
        qa_btn.click(qa_interface, question_input, qa_output)


if __name__ == "__main__":
    demo.queue().launch()
