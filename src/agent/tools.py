"""–ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã –¥–ª—è RAG-–∞–≥–µ–Ω—Ç–∞."""

import json
import logging
import re
from datetime import datetime
from pathlib import Path
from typing import Optional, Any

import numpy as np
from langchain_core.tools import tool

from src.config import list_existing_dbs, CHUNKS_LOG_DIR
from src.rag.retriever import (
    retrieve_with_reranking,
    retrieve_chunks,
    get_neighbor_chunks,
    format_context_with_citations,
    get_article_titles,
    RetrievedChunk,
    ConfidenceLevel,
    ConfidenceScore,
)

logger = logging.getLogger(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ —Å–µ—Å—Å–∏–∏ –∞–≥–µ–Ω—Ç–∞
_current_agent_session_dir: Optional[Path] = None


def _get_agent_session_dir() -> Path:
    """–ü–æ–ª—É—á–∏—Ç—å –∏–ª–∏ —Å–æ–∑–¥–∞—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ç–µ–∫—É—â–µ–π —Å–µ—Å—Å–∏–∏ –∞–≥–µ–Ω—Ç–∞."""
    global _current_agent_session_dir
    if _current_agent_session_dir is None:
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        _current_agent_session_dir = CHUNKS_LOG_DIR / f"{timestamp}_agent"
        _current_agent_session_dir.mkdir(parents=True, exist_ok=True)
        logger.info(
            "üìÅ –°–æ–∑–¥–∞–Ω–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –ª–æ–≥–æ–≤ –∞–≥–µ–Ω—Ç–∞: %s", _current_agent_session_dir
        )
    return _current_agent_session_dir


def reset_agent_session_dir() -> None:
    """–°–±—Ä–æ—Å–∏—Ç—å –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å–µ—Å—Å–∏–∏ –∞–≥–µ–Ω—Ç–∞ (–¥–ª—è –Ω–æ–≤–æ–π —Å–µ—Å—Å–∏–∏)."""
    global _current_agent_session_dir
    _current_agent_session_dir = None


def _convert_numpy_types(obj: Any) -> Any:
    """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏.

    Args:
        obj: –û–±—ä–µ–∫—Ç –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è

    Returns:
        –û–±—ä–µ–∫—Ç —Å –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–Ω—ã–º–∏ —Ç–∏–ø–∞–º–∏
    """
    if isinstance(obj, (np.integer, np.floating)):
        return float(obj) if isinstance(obj, np.floating) else int(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: _convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, (list, tuple)):
        return [_convert_numpy_types(item) for item in obj]
    elif isinstance(obj, set):
        return {_convert_numpy_types(item) for item in obj}
    else:
        return obj


def _save_agent_chunks(
    chunks: list[RetrievedChunk],
    query: str,
    tool_name: str,
    confidence: Optional[ConfidenceScore] = None,
    query_type: Optional[str] = None,
    expanded_chunks: Optional[list[RetrievedChunk]] = None,
) -> str:
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —á–∞–Ω–∫–∏, –ø–æ–ª—É—á–µ–Ω–Ω—ã–µ –∞–≥–µ–Ω—Ç–æ–º, –≤ JSON —Ñ–∞–π–ª.

    Args:
        chunks: –°–ø–∏—Å–æ–∫ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å
        tool_name: –ò–º—è –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞
        confidence: –û—Ü–µ–Ω–∫–∞ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        query_type: –¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞
        expanded_chunks: –°–ø–∏—Å–æ–∫ —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã—Ö —á–∞–Ω–∫–æ–≤ (–µ—Å–ª–∏ –µ—Å—Ç—å)

    Returns:
        –ü—É—Ç—å –∫ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–º—É —Ñ–∞–π–ª—É
    """
    session_dir = _get_agent_session_dir()

    # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –∏–º—è —Ñ–∞–π–ª–∞ –∏–∑ –∑–∞–ø—Ä–æ—Å–∞
    safe_query = re.sub(r"[^\w\s-]", "", query[:50]).strip().replace(" ", "_")
    timestamp = datetime.now().strftime("%H%M%S")
    filepath = session_dir / f"{timestamp}_{safe_query}.json"

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–∞–∫–∏–µ —á–∞–Ω–∫–∏ –±—ã–ª–∏ —Ä–∞—Å—à–∏—Ä–µ–Ω—ã
    expanded_ids = set()
    if expanded_chunks:
        expanded_ids = {f"{c.file_hash}_{c.chunk_id}" for c in expanded_chunks}

    # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ –æ —á–∞–Ω–∫–∞—Ö
    chunks_data = []
    for chunk in chunks:
        chunk_key = f"{chunk.file_hash}_{chunk.chunk_id}"
        chunks_data.append(
            {
                "chunk_id": chunk.chunk_id,
                "file_name": chunk.file_name,
                "file_hash": chunk.file_hash,
                "page": chunk.page,
                "section": chunk.section,
                "distance": chunk.distance,
                "reranked_score": chunk.reranked_score,
                "text": chunk.text,
                "is_expanded": chunk_key in expanded_ids,
            }
        )

    # –§–æ—Ä–º–∏—Ä—É–µ–º –∏—Ç–æ–≥–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    data = {
        "tool_name": tool_name,
        "query": query,
        "query_type": query_type,
        "timestamp": datetime.now().isoformat(),
        "total_chunks": len(chunks),
        "expanded_chunks_count": len(expanded_chunks) if expanded_chunks else 0,
        "sources": sorted(set(c.file_name for c in chunks)),
        "chunks": chunks_data,
    }

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ confidence –µ—Å–ª–∏ –µ—Å—Ç—å
    if confidence:
        data["confidence"] = {
            "level": confidence.level.value,
            "score": confidence.score,
            "avg_distance": confidence.avg_distance,
            "min_distance": confidence.min_distance,
            "max_distance": confidence.max_distance,
            "num_chunks": confidence.num_chunks,
            "num_sources": confidence.num_sources,
            "coverage_by_section": confidence.coverage_by_section,
            "warnings": confidence.warnings,
        }

    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º numpy —Ç–∏–ø—ã –≤ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ Python —Ç–∏–ø—ã –¥–ª—è JSON —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏–∏
    data = _convert_numpy_types(data)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Ñ–∞–π–ª
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

    logger.info("üíæ –ß–∞–Ω–∫–∏ –∞–≥–µ–Ω—Ç–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã: %s", filepath)
    return str(filepath)


@tool
def search_vector_db(
    query: str,
    db_name: str,
    n_results: int = 5,
    expand_context: bool = True,
    section_filter: Optional[str] = None,
) -> str:
    """–ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.

    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç—å—è—Ö.
    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Å–µ–∫—Ü–∏–π.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ.
               –§–æ—Ä–º—É–ª–∏—Ä—É–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ.
        db_name: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'climate').
                 –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å —á–µ—Ä–µ–∑ list_available_databases.
        n_results: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5).
        expand_context: –î–æ–±–∞–≤–ª—è—Ç—å —Å–æ—Å–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True).
        section_filter: –§–∏–ª—å—Ç—Ä –ø–æ —Å–µ–∫—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).
                       –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 'abstract', 'introduction', 'methods',
                       'results', 'discussion', 'conclusion'.

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ü–∏—Ç–∞—Ç–∞–º–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
    """
    logger.info("üîß Tool search_vector_db: query='%s...', db='%s'", query[:50], db_name)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ë–î"
        return f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{db_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î: {available}"

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞–Ω–∫–∏ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º
    initial_chunks, query_type, confidence = retrieve_with_reranking(
        query=query,
        db_name=db_name,
        n_results=n_results,
        section_filter=section_filter,
        file_name_filter=None,
        fetch_multiplier=3,
    )

    if not initial_chunks:
        return f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'"

    # –†–∞—Å—à–∏—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Å–µ–¥–Ω–∏–º–∏ —á–∞–Ω–∫–∞–º–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    chunks = initial_chunks
    if expand_context:
        seen_ids = {f"{c.file_hash}_{c.chunk_id}" for c in initial_chunks}
        expanded_chunks = []

        # –†–∞—Å—à–∏—Ä—è–µ–º —Ç–æ–ø-3 —á–∞–Ω–∫–∞
        for chunk in initial_chunks[:3]:
            neighbors = get_neighbor_chunks(chunk, db_name, window=1, query=query)
            for n in neighbors:
                key = f"{n.file_hash}_{n.chunk_id}"
                if key not in seen_ids:
                    expanded_chunks.append(n)
                    seen_ids.add(key)

        chunks = initial_chunks + expanded_chunks

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context = format_context_with_citations(chunks[:10])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫–∏ –≤ –ª–æ–≥
    _save_agent_chunks(
        chunks=chunks,
        query=query,
        tool_name="search_vector_db",
        confidence=confidence,
        query_type=query_type,
        expanded_chunks=expanded_chunks if expand_context else None,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    level_text = {
        ConfidenceLevel.HIGH: "–í–´–°–û–ö–ê–Ø",
        ConfidenceLevel.MEDIUM: "–°–†–ï–î–ù–Ø–Ø",
        ConfidenceLevel.LOW: "–ù–ò–ó–ö–ê–Ø",
        ConfidenceLevel.VERY_LOW: "–û–ß–ï–ù–¨ –ù–ò–ó–ö–ê–Ø",
    }.get(confidence.level, "–ù–ï–ò–ó–í–ï–°–¢–ù–ê")

    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    sources = sorted(set(c.file_name for c in chunks))

    result = f"""üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
–ó–∞–ø—Ä–æ—Å: {query}
–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_type}
–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {level_text} (score: {confidence.score:.2f})
–°—Ä–µ–¥–Ω—è—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è: {confidence.avg_distance:.3f}
–ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {len(sources)}
"""

    if confidence.warnings:
        result += f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {'; '.join(confidence.warnings)}\n"

    result += f"""
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:
{chr(10).join(f'‚Ä¢ {s}' for s in sources)}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:

{context}
"""

    logger.info("‚úÖ Tool search_vector_db: –Ω–∞–π–¥–µ–Ω–æ %d —á–∞–Ω–∫–æ–≤", len(chunks))
    return result


@tool
def list_available_databases() -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞.

    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –∫–∞–∫–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–æ—Å—Ç—É–ø–Ω—ã
    –¥–ª—è –ø–æ–∏—Å–∫–∞ –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π.

    Returns:
        –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º.
    """
    logger.info("üîß Tool list_available_databases called")

    existing_dbs = list_existing_dbs()

    if not existing_dbs:
        return (
            "‚ùå –ù–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –±–∞–∑ –¥–∞–Ω–Ω—ã—Ö. –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞—Ç—å —Å—Ç–∞—Ç—å–∏."
        )

    result = "üìö –î–û–°–¢–£–ü–ù–´–ï –ë–ê–ó–´ –î–ê–ù–ù–´–•:\n\n"
    for db_name in existing_dbs:
        result += f"‚Ä¢ {db_name}\n"

    result += (
        "\n–ò—Å–ø–æ–ª—å–∑—É–π –Ω–∞–∑–≤–∞–Ω–∏–µ –ë–î –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–µ db_name –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∞ search_vector_db."
    )

    logger.info("‚úÖ Tool list_available_databases: –Ω–∞–π–¥–µ–Ω–æ %d –ë–î", len(existing_dbs))
    return result


@tool
def search_by_section(
    query: str,
    db_name: str,
    sections: list[str],
    n_results_per_section: int = 3,
) -> str:
    """–ü–æ–∏—Å–∫ –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Å–µ–∫—Ü–∏—è—Ö —Å—Ç–∞—Ç–µ–π –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.

    –ü–æ–ª–µ–∑–Ω–æ –∫–æ–≥–¥–∞ –Ω—É–∂–Ω–æ –Ω–∞–π—Ç–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ —Ä–∞–∑–Ω—ã—Ö —á–∞—Å—Ç–µ–π —Å—Ç–∞—Ç–µ–π:
    –Ω–∞–ø—Ä–∏–º–µ—Ä, –º–µ—Ç–æ–¥—ã –ò —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ.

    –í–ê–ñ–ù–û: –°–µ–∫—Ü–∏—è 'unknown' –í–°–ï–ì–î–ê –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –¥–æ–±–∞–≤–ª—è–µ—Ç—Å—è –∫ –ø–æ–∏—Å–∫—É,
    —Ç–∞–∫ –∫–∞–∫ —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å–µ–∫—Ü–∏–∏ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ.
    –≠—Ç–æ –≥–∞—Ä–∞–Ω—Ç–∏—Ä—É–µ—Ç, —á—Ç–æ –Ω–µ –±—É–¥—É—Ç –ø—Ä–æ–ø—É—â–µ–Ω—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ.
        db_name: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞.
        sections: –°–ø–∏—Å–æ–∫ —Å–µ–∫—Ü–∏–π –¥–ª—è –ø–æ–∏—Å–∫–∞.
                 –î–æ–ø—É—Å—Ç–∏–º—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 'abstract', 'introduction', 'methods',
                 'results', 'discussion', 'conclusion'.
                 –°–µ–∫—Ü–∏—è 'unknown' –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ.
        n_results_per_section: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –Ω–∞ —Å–µ–∫—Ü–∏—é (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 3).

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ —É–∫–∞–∑–∞–Ω–Ω—ã—Ö —Å–µ–∫—Ü–∏–π.
    """
    logger.info(
        "üîß Tool search_by_section: query='%s...', sections=%s", query[:50], sections
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ë–î"
        return f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{db_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î: {available}"

    # –í—Å–µ–≥–¥–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Å–µ–∫—Ü–∏—é 'unknown', –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ
    # –≠—Ç–æ –≤–∞–∂–Ω–æ, —Ç–∞–∫ –∫–∞–∫ —Ä–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å–µ–∫—Ü–∏–∏ –Ω–µ –≤—Å–µ–≥–¥–∞ –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ
    sections_to_search = list(sections)
    if "unknown" not in sections_to_search:
        sections_to_search.append("unknown")

    all_chunks: list[RetrievedChunk] = []
    section_results = {}

    for section in sections_to_search:
        chunks = retrieve_chunks(
            query=query,
            db_name=db_name,
            n_results=n_results_per_section,
            section_filter=section,
            file_name_filter=None,
        )
        section_results[section] = len(chunks)
        all_chunks.extend(chunks)

    if not all_chunks:
        return f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'"

    # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ distance
    all_chunks.sort(key=lambda c: c.distance)

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫–∏ –≤ –ª–æ–≥
    _save_agent_chunks(
        chunks=all_chunks,
        query=query,
        tool_name="search_by_section",
        query_type=f"sections:{','.join(sections_to_search)}",
    )

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    context = format_context_with_citations(all_chunks[:10])
    sources = sorted(set(c.file_name for c in all_chunks))

    result = f"""üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê –ü–û –°–ï–ö–¶–ò–Ø–ú
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
–ó–∞–ø—Ä–æ—Å: {query}
–°–µ–∫—Ü–∏–∏: {', '.join(sections_to_search)}
–ù–∞–π–¥–µ–Ω–æ –ø–æ —Å–µ–∫—Ü–∏—è–º: {section_results}
–í—Å–µ–≥–æ —á–∞–Ω–∫–æ–≤: {len(all_chunks)}
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {len(sources)}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:
{chr(10).join(f'‚Ä¢ {s}' for s in sources)}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:

{context}
"""

    logger.info("‚úÖ Tool search_by_section: –Ω–∞–π–¥–µ–Ω–æ %d —á–∞–Ω–∫–æ–≤", len(all_chunks))
    return result


@tool
def list_article_titles(db_name: str) -> str:
    """–ü–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π –≤—Å–µ—Ö —Å—Ç–∞—Ç–µ–π –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö.

    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, —á—Ç–æ–±—ã —É–∑–Ω–∞—Ç—å –∫–∞–∫–∏–µ —Å—Ç–∞—Ç—å–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
    –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö. –≠—Ç–æ –ø–æ–º–æ–∂–µ—Ç –≤—ã–±—Ä–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—É—é —Å—Ç–∞—Ç—å—é
    –¥–ª—è –ø–æ–∏—Å–∫–∞ —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é.

    Args:
        db_name: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'climate').

    Returns:
        –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤–∞–Ω–∏–π —Å—Ç–∞—Ç–µ–π —Å –∏—Ö –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ–º.
    """
    logger.info("üîß Tool list_article_titles: db_name='%s'", db_name)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ë–î"
        return f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{db_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î: {available}"

    try:
        titles = get_article_titles(db_name)

        if not titles:
            return f"‚ùå –í –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö '{db_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å—Ç–∞—Ç–µ–π."

        result = f"üìö –°–¢–ê–¢–¨–ò –í –ë–ê–ó–ï –î–ê–ù–ù–´–• '{db_name}':\n\n"
        result += f"–í—Å–µ–≥–æ —Å—Ç–∞—Ç–µ–π: {len(titles)}\n\n"

        for i, title in enumerate(titles, 1):
            result += f"{i}. {title}\n"

        result += (
            "\n–ò—Å–ø–æ–ª—å–∑—É–π —Ç–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ –≤ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–µ "
            "search_vector_db_by_article –¥–ª—è –ø–æ–∏—Å–∫–∞ —Ç–æ–ª—å–∫–æ –≤ —ç—Ç–æ–π —Å—Ç–∞—Ç—å–µ."
        )

        logger.info("‚úÖ Tool list_article_titles: –Ω–∞–π–¥–µ–Ω–æ %d —Å—Ç–∞—Ç–µ–π", len(titles))
        return result
    except Exception as e:
        logger.exception("–û—à–∏–±–∫–∞ –≤ list_article_titles")
        return f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–ø–∏—Å–∫–∞ —Å—Ç–∞—Ç–µ–π: {e}"


@tool
def search_vector_db_by_article(
    query: str,
    db_name: str,
    article_title: str,
    n_results: int = 5,
    expand_context: bool = True,
    section_filter: Optional[str] = None,
) -> str:
    """–ü–æ–∏—Å–∫ –≤ –≤–µ–∫—Ç–æ—Ä–Ω–æ–π –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö —Å —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å—Ç–∞—Ç—å–∏.

    –ò—Å–ø–æ–ª—å–∑—É–π —ç—Ç–æ—Ç –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π —Å—Ç–∞—Ç—å–µ.
    –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã —Ç–µ–∫—Å—Ç–∞ —Ç–æ–ª—å–∫–æ –∏–∑ —É–∫–∞–∑–∞–Ω–Ω–æ–π —Å—Ç–∞—Ç—å–∏
    —Å —É–∫–∞–∑–∞–Ω–∏–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, —Å—Ç—Ä–∞–Ω–∏—Ü –∏ —Å–µ–∫—Ü–∏–π.

    Args:
        query: –ü–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å –Ω–∞ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–º —è–∑—ã–∫–µ.
               –§–æ—Ä–º—É–ª–∏—Ä—É–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ.
        db_name: –ò–º—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ–∏—Å–∫–∞ (–Ω–∞–ø—Ä–∏–º–µ—Ä, 'climate').
                 –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î –º–æ–∂–Ω–æ —É–∑–Ω–∞—Ç—å —á–µ—Ä–µ–∑ list_available_databases.
        article_title: –¢–æ—á–Ω–æ–µ –Ω–∞–∑–≤–∞–Ω–∏–µ —Å—Ç–∞—Ç—å–∏ (—Ñ–∞–π–ª–∞) –¥–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏.
                      –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å —á–µ—Ä–µ–∑ list_article_titles.
        n_results: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 5).
        expand_context: –î–æ–±–∞–≤–ª—è—Ç—å —Å–æ—Å–µ–¥–Ω–∏–µ —á–∞–Ω–∫–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True).
        section_filter: –§–∏–ª—å—Ç—Ä –ø–æ —Å–µ–∫—Ü–∏–∏ —Å—Ç–∞—Ç—å–∏ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ).
                       –í–æ–∑–º–æ–∂–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è: 'abstract', 'introduction', 'methods',
                       'results', 'discussion', 'conclusion'.

    Returns:
        –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å —Ü–∏—Ç–∞—Ç–∞–º–∏ –∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏.
    """
    logger.info(
        "üîß Tool search_vector_db_by_article: query='%s...', db='%s', article='%s'",
        query[:50],
        db_name,
        article_title,
    )

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ –ë–î
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "–Ω–µ—Ç –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ë–î"
        return f"‚ùå –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö '{db_name}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –î–æ—Å—Ç—É–ø–Ω—ã–µ –ë–î: {available}"

    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∞–Ω–∫–∏ —Å —Ä–µ—Ä–∞–Ω–∫–∏–Ω–≥–æ–º –∏ —Ñ–∏–ª—å—Ç—Ä–æ–º –ø–æ –Ω–∞–∑–≤–∞–Ω–∏—é —Å—Ç–∞—Ç—å–∏
    initial_chunks, query_type, confidence = retrieve_with_reranking(
        query=query,
        db_name=db_name,
        n_results=n_results,
        section_filter=section_filter,
        file_name_filter=article_title,
        fetch_multiplier=3,
    )

    if not initial_chunks:
        return (
            f"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ñ—Ä–∞–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}' "
            f"–≤ —Å—Ç–∞—Ç—å–µ '{article_title}'"
        )

    # –†–∞—Å—à–∏—Ä—è–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç —Å–æ—Å–µ–¥–Ω–∏–º–∏ —á–∞–Ω–∫–∞–º–∏, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    chunks = initial_chunks
    if expand_context:
        seen_ids = {f"{c.file_hash}_{c.chunk_id}" for c in initial_chunks}
        expanded_chunks = []

        # –†–∞—Å—à–∏—Ä—è–µ–º —Ç–æ–ø-3 —á–∞–Ω–∫–∞
        for chunk in initial_chunks[:3]:
            neighbors = get_neighbor_chunks(chunk, db_name, window=1, query=query)
            for n in neighbors:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —Å–æ—Å–µ–¥–Ω–∏–π —á–∞–Ω–∫ –∏–∑ —Ç–æ–π –∂–µ —Å—Ç–∞—Ç—å–∏
                if n.file_name == article_title:
                    key = f"{n.file_hash}_{n.chunk_id}"
                    if key not in seen_ids:
                        expanded_chunks.append(n)
                        seen_ids.add(key)

        chunks = initial_chunks + expanded_chunks

    # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
    context = format_context_with_citations(chunks[:10])

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —á–∞–Ω–∫–∏ –≤ –ª–æ–≥
    _save_agent_chunks(
        chunks=chunks,
        query=query,
        tool_name="search_vector_db_by_article",
        confidence=confidence,
        query_type=query_type,
        expanded_chunks=expanded_chunks if expand_context else None,
    )

    # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
    level_text = {
        ConfidenceLevel.HIGH: "–í–´–°–û–ö–ê–Ø",
        ConfidenceLevel.MEDIUM: "–°–†–ï–î–ù–Ø–Ø",
        ConfidenceLevel.LOW: "–ù–ò–ó–ö–ê–Ø",
        ConfidenceLevel.VERY_LOW: "–û–ß–ï–ù–¨ –ù–ò–ó–ö–ê–Ø",
    }.get(confidence.level, "–ù–ï–ò–ó–í–ï–°–¢–ù–ê")

    # –°–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
    sources = sorted(set(c.file_name for c in chunks))

    result = f"""üìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ü–û–ò–°–ö–ê –í –°–¢–ê–¢–¨–ï
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ
–ó–∞–ø—Ä–æ—Å: {query}
–°—Ç–∞—Ç—å—è: {article_title}
–¢–∏–ø –∑–∞–ø—Ä–æ—Å–∞: {query_type}
–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {level_text} (score: {confidence.score:.2f})
–°—Ä–µ–¥–Ω—è—è –¥–∏—Å—Ç–∞–Ω—Ü–∏—è: {confidence.avg_distance:.3f}
–ù–∞–π–¥–µ–Ω–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: {len(sources)}
"""

    if confidence.warnings:
        result += f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {'; '.join(confidence.warnings)}\n"

    result += f"""
‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ù–´–ï –ò–°–¢–û–ß–ù–ò–ö–ò:
{chr(10).join(f'‚Ä¢ {s}' for s in sources)}

‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ

–ù–ê–ô–î–ï–ù–ù–´–ï –§–†–ê–ì–ú–ï–ù–¢–´:

{context}
"""

    logger.info("‚úÖ Tool search_vector_db_by_article: –Ω–∞–π–¥–µ–Ω–æ %d —á–∞–Ω–∫–æ–≤", len(chunks))
    return result


# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã
ALL_TOOLS = [
    search_vector_db,
    list_available_databases,
    search_by_section,
    list_article_titles,
    search_vector_db_by_article,
]

# –≠–∫—Å–ø–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
__all__ = [
    "ALL_TOOLS",
    "search_vector_db",
    "list_available_databases",
    "search_by_section",
    "list_article_titles",
    "search_vector_db_by_article",
    "reset_agent_session_dir",
]
