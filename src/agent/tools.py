"""Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ RAG-Ğ°Ğ³ĞµĞ½Ñ‚Ğ°."""

import logging
from typing import Optional

from langchain_core.tools import tool

from src.config import list_existing_dbs
from src.rag.retriever import (
    retrieve_with_reranking,
    retrieve_chunks,
    get_neighbor_chunks,
    format_context_with_citations,
    RetrievedChunk,
    ConfidenceLevel,
)

logger = logging.getLogger(__name__)


@tool
def search_vector_db(
    query: str,
    db_name: str,
    n_results: int = 5,
    expand_context: bool = True,
    section_filter: Optional[str] = None,
) -> str:
    """ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ±Ğ°Ğ·Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹.

    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ğ¾Ğ¹ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ğ¸ Ğ² Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ÑŒÑÑ….
    Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ñ‹ Ñ‚ĞµĞºÑÑ‚Ğ° Ñ ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¾Ğ², ÑÑ‚Ñ€Ğ°Ğ½Ğ¸Ñ† Ğ¸ ÑĞµĞºÑ†Ğ¸Ğ¹.

    Args:
        query: ĞŸĞ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.
               Ğ¤Ğ¾Ñ€Ğ¼ÑƒĞ»Ğ¸Ñ€ÑƒĞ¹ Ğ¼Ğ°ĞºÑĞ¸Ğ¼Ğ°Ğ»ÑŒĞ½Ğ¾ ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ¾.
        db_name: Ğ˜Ğ¼Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, 'climate').
                 Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ‘Ğ” Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· list_available_databases.
        n_results: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 5).
        expand_context: Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑÑ‚ÑŒ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğµ Ñ‡Ğ°Ğ½ĞºĞ¸ Ğ´Ğ»Ñ Ñ€Ğ°ÑÑˆĞ¸Ñ€ĞµĞ½Ğ¸Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ° (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ True).
        section_filter: Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ Ğ¿Ğ¾ ÑĞµĞºÑ†Ğ¸Ğ¸ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸ (Ğ¾Ğ¿Ñ†Ğ¸Ğ¾Ğ½Ğ°Ğ»ÑŒĞ½Ğ¾).
                       Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ: 'abstract', 'introduction', 'methods',
                       'results', 'discussion', 'conclusion'.

    Returns:
        Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸ĞµĞ¹ Ğ¾Ğ± ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸.
    """
    logger.info("ğŸ”§ Tool search_vector_db: query='%s...', db='%s'", query[:50], db_name)

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ‘Ğ”
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "Ğ½ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ‘Ğ”"
        return f"âŒ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… '{db_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°. Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ‘Ğ”: {available}"

    # Ğ˜Ğ·Ğ²Ğ»ĞµĞºĞ°ĞµĞ¼ Ñ‡Ğ°Ğ½ĞºĞ¸ Ñ Ñ€ĞµÑ€Ğ°Ğ½ĞºĞ¸Ğ½Ğ³Ğ¾Ğ¼
    initial_chunks, query_type, confidence = retrieve_with_reranking(
        query=query,
        db_name=db_name,
        n_results=n_results,
        section_filter=section_filter,
        fetch_multiplier=3,
    )

    if not initial_chunks:
        return f"âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: '{query}'"

    # Ğ Ğ°ÑÑˆĞ¸Ñ€ÑĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ ÑĞ¾ÑĞµĞ´Ğ½Ğ¸Ğ¼Ğ¸ Ñ‡Ğ°Ğ½ĞºĞ°Ğ¼Ğ¸, ĞµÑĞ»Ğ¸ Ğ½ÑƒĞ¶Ğ½Ğ¾
    chunks = initial_chunks
    if expand_context:
        seen_ids = {f"{c.file_hash}_{c.chunk_id}" for c in initial_chunks}
        expanded_chunks = []

        # Ğ Ğ°ÑÑˆĞ¸Ñ€ÑĞµĞ¼ Ñ‚Ğ¾Ğ¿-3 Ñ‡Ğ°Ğ½ĞºĞ°
        for chunk in initial_chunks[:3]:
            neighbors = get_neighbor_chunks(chunk, db_name, window=1, query=query)
            for n in neighbors:
                key = f"{n.file_hash}_{n.chunk_id}"
                if key not in seen_ids:
                    expanded_chunks.append(n)
                    seen_ids.add(key)

        chunks = initial_chunks + expanded_chunks

    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚
    context = format_context_with_citations(chunks[:10])

    # Ğ”Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¾Ğ± ÑƒĞ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚Ğ¸
    level_text = {
        ConfidenceLevel.HIGH: "Ğ’Ğ«Ğ¡ĞĞšĞĞ¯",
        ConfidenceLevel.MEDIUM: "Ğ¡Ğ Ğ•Ğ”ĞĞ¯Ğ¯",
        ConfidenceLevel.LOW: "ĞĞ˜Ğ—ĞšĞĞ¯",
        ConfidenceLevel.VERY_LOW: "ĞĞ§Ğ•ĞĞ¬ ĞĞ˜Ğ—ĞšĞĞ¯",
    }.get(confidence.level, "ĞĞ•Ğ˜Ğ—Ğ’Ğ•Ğ¡Ğ¢ĞĞ")

    # Ğ¡Ğ¾Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¸ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸
    sources = sorted(set(c.file_name for c in chunks))

    result = f"""ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ĞŸĞĞ˜Ğ¡ĞšĞ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ: {query}
Ğ¢Ğ¸Ğ¿ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: {query_type}
Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {level_text} (score: {confidence.score:.2f})
Ğ¡Ñ€ĞµĞ´Ğ½ÑÑ Ğ´Ğ¸ÑÑ‚Ğ°Ğ½Ñ†Ğ¸Ñ: {confidence.avg_distance:.3f}
ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: {len(chunks)}
Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸: {len(sources)}
"""

    if confidence.warnings:
        result += f"âš ï¸ ĞŸÑ€ĞµĞ´ÑƒĞ¿Ñ€ĞµĞ¶Ğ´ĞµĞ½Ğ¸Ñ: {'; '.join(confidence.warnings)}\n"

    result += f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ• Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜:
{chr(10).join(f'â€¢ {s}' for s in sources)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ĞĞĞ™Ğ”Ğ•ĞĞĞ«Ğ• Ğ¤Ğ ĞĞ“ĞœĞ•ĞĞ¢Ğ«:

{context}
"""

    logger.info("âœ… Tool search_vector_db: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ %d Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²", len(chunks))
    return result


@tool
def list_available_databases() -> str:
    """ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ±Ğ°Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.

    Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ ÑÑ‚Ğ¾Ñ‚ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚, Ñ‡Ñ‚Ğ¾Ğ±Ñ‹ ÑƒĞ·Ğ½Ğ°Ñ‚ÑŒ ĞºĞ°ĞºĞ¸Ğµ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹
    Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ½Ğ°ÑƒÑ‡Ğ½Ñ‹Ñ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹.

    Returns:
        Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ±Ğ°Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸ĞµĞ¼.
    """
    logger.info("ğŸ”§ Tool list_available_databases called")

    existing_dbs = list_existing_dbs()

    if not existing_dbs:
        return (
            "âŒ ĞĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ±Ğ°Ğ· Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…. ĞĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾ ÑĞ½Ğ°Ñ‡Ğ°Ğ»Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ½Ğ´ĞµĞºÑĞ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑŒĞ¸."
        )

    result = "ğŸ“š Ğ”ĞĞ¡Ğ¢Ğ£ĞŸĞĞ«Ğ• Ğ‘ĞĞ—Ğ« Ğ”ĞĞĞĞ«Ğ¥:\n\n"
    for db_name in existing_dbs:
        result += f"â€¢ {db_name}\n"

    result += (
        "\nĞ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞ¹ Ğ½Ğ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ‘Ğ” Ğ² Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğµ db_name Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ° search_vector_db."
    )

    logger.info("âœ… Tool list_available_databases: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ %d Ğ‘Ğ”", len(existing_dbs))
    return result


@tool
def search_by_section(
    query: str,
    db_name: str,
    sections: list[str],
    n_results_per_section: int = 3,
) -> str:
    """ĞŸĞ¾Ğ¸ÑĞº Ğ² Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¸Ñ… ÑĞµĞºÑ†Ğ¸ÑÑ… ÑÑ‚Ğ°Ñ‚ĞµĞ¹ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾.

    ĞŸĞ¾Ğ»ĞµĞ·Ğ½Ğ¾ ĞºĞ¾Ğ³Ğ´Ğ° Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ· Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‡Ğ°ÑÑ‚ĞµĞ¹ ÑÑ‚Ğ°Ñ‚ĞµĞ¹:
    Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€, Ğ¼ĞµÑ‚Ğ¾Ğ´Ñ‹ Ğ˜ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾.

    Args:
        query: ĞŸĞ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğ¹ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ½Ğ° ĞµÑÑ‚ĞµÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ.
        db_name: Ğ˜Ğ¼Ñ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.
        sections: Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº ÑĞµĞºÑ†Ğ¸Ğ¹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ°.
                 Ğ”Ğ¾Ğ¿ÑƒÑÑ‚Ğ¸Ğ¼Ñ‹Ğµ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ñ: 'abstract', 'introduction', 'methods',
                 'results', 'discussion', 'conclusion'.
        n_results_per_section: ĞšĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ¾ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ² Ğ½Ğ° ÑĞµĞºÑ†Ğ¸Ñ (Ğ¿Ğ¾ ÑƒĞ¼Ğ¾Ğ»Ñ‡Ğ°Ğ½Ğ¸Ñ 3).

    Returns:
        Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ğ¸Ğ· ÑƒĞºĞ°Ğ·Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞµĞºÑ†Ğ¸Ğ¹.
    """
    logger.info(
        "ğŸ”§ Tool search_by_section: query='%s...', sections=%s", query[:50], sections
    )

    # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼ ÑÑƒÑ‰ĞµÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ‘Ğ”
    existing_dbs = list_existing_dbs()
    if db_name not in existing_dbs:
        available = ", ".join(existing_dbs) if existing_dbs else "Ğ½ĞµÑ‚ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ‘Ğ”"
        return f"âŒ Ğ‘Ğ°Ğ·Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… '{db_name}' Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°. Ğ”Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ‘Ğ”: {available}"

    all_chunks: list[RetrievedChunk] = []
    section_results = {}

    for section in sections:
        chunks = retrieve_chunks(
            query=query,
            db_name=db_name,
            n_results=n_results_per_section,
            section_filter=section,
        )
        section_results[section] = len(chunks)
        all_chunks.extend(chunks)

    if not all_chunks:
        return f"âŒ ĞĞµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ñ€ĞµĞ»ĞµĞ²Ğ°Ğ½Ñ‚Ğ½Ñ‹Ñ… Ñ„Ñ€Ğ°Ğ³Ğ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°: '{query}'"

    # Ğ¡Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ¿Ğ¾ distance
    all_chunks.sort(key=lambda c: c.distance)

    # Ğ¤Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    context = format_context_with_citations(all_chunks[:10])
    sources = sorted(set(c.file_name for c in all_chunks))

    result = f"""ğŸ“Š Ğ Ğ•Ğ—Ğ£Ğ›Ğ¬Ğ¢ĞĞ¢Ğ« ĞŸĞĞ˜Ğ¡ĞšĞ ĞŸĞ Ğ¡Ğ•ĞšĞ¦Ğ˜Ğ¯Ğœ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
Ğ—Ğ°Ğ¿Ñ€Ğ¾Ñ: {query}
Ğ¡ĞµĞºÑ†Ğ¸Ğ¸: {', '.join(sections)}
ĞĞ°Ğ¹Ğ´ĞµĞ½Ğ¾ Ğ¿Ğ¾ ÑĞµĞºÑ†Ğ¸ÑĞ¼: {section_results}
Ğ’ÑĞµĞ³Ğ¾ Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²: {len(all_chunks)}
Ğ˜ÑÑ‚Ğ¾Ñ‡Ğ½Ğ¸ĞºĞ¸: {len(sources)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Ğ˜Ğ¡ĞŸĞĞ›Ğ¬Ğ—ĞĞ’ĞĞĞĞ«Ğ• Ğ˜Ğ¡Ğ¢ĞĞ§ĞĞ˜ĞšĞ˜:
{chr(10).join(f'â€¢ {s}' for s in sources)}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ĞĞĞ™Ğ”Ğ•ĞĞĞ«Ğ• Ğ¤Ğ ĞĞ“ĞœĞ•ĞĞ¢Ğ«:

{context}
"""

    logger.info("âœ… Tool search_by_section: Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ¾ %d Ñ‡Ğ°Ğ½ĞºĞ¾Ğ²", len(all_chunks))
    return result


# Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚Ğ¸Ñ€ÑƒĞµĞ¼ Ğ²ÑĞµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹
ALL_TOOLS = [
    search_vector_db,
    list_available_databases,
    search_by_section,
]
